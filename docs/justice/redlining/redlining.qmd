---
title: "Historic Redlining"
format: gfm
---

## Philadelphia example
The Census Home Owners' Loan Corporation (HOLC) dataset, available on GitHub, is a valuable resource containing historical data about the process of redlining in the United States. Redlining is a discriminatory practice that involves denying loans or insurance to people living in specific neighborhoods, often based on race or ethnicity. The dataset provides details on the HOLC risk classifications, neighborhood boundaries, and descriptions for over 200 cities across the United States from the 1930s.
 
Historic redlining data refers to data from the Home Owners' Loan Corporation (HOLC) that created residential security maps in the 1930s, which contributed to racial segregation and disinvestment in minority neighborhoods. One popular source for this data is the Mapping Inequality project (https://dsl.richmond.edu/panorama/redlining/).

In this example, we'll download historic redlining data for Philadelphia in the form of a GeoJSON file and analyze the data in R and Python.

R:
In R, we'll use the 'sf' and 'dplyr' packages to read and process the GeoJSON data.

R code:

```{r, cache=TRUE}
# Install and load necessary libraries]
library(knitr)
library(sf)
library(dplyr)

# Download historic redlining data for Philadelphia
url <- "https://dsl.richmond.edu/panorama/redlining/static/downloads/geojson/PAPhiladelphia1937.geojson"
philly_geojson <- read_sf(url)

# Count the number of areas per HOLC grade
grade_counts <- philly_geojson %>%
  group_by(holc_grade) %>%
  summarize(count = n())

kable(head(philly_geojson))
plot(grade_counts)
```


Python:
In Python, we'll use the 'geopandas' library to read and process the GeoJSON data.

Python code:

```{python, cache=TRUE}
# Install necessary libraries


import geopandas as gpd

# Download historic redlining data for Philadelphia
url = "https://dsl.richmond.edu/panorama/redlining/static/downloads/geojson/PAPhiladelphia1937.geojson"
philly_geojson = gpd.read_file(url)

# Count the number of areas per HOLC grade
grade_counts = philly_geojson["holc_grade"].value_counts()
print(grade_counts)
```


In conclusion, both R and Python offer efficient ways to download and process historic redlining data in the form of GeoJSON files. The 'sf' package in R provides a simple way to read and manipulate spatial data, while the 'geopandas' library in Python offers similar functionality. The 'dplyr' package in R can be used for data manipulation and analysis, and Python's built-in functions like value_counts() can be used for aggregating data. Depending on your preferred programming language and environment, both options can be effective for working with historic redlining data.

## Per census track

Downloading and plotting the dataset in R:

R code:

```{r, cache=TRUE}

# Load libraries
library(sf)
library(ggplot2)

# Download the dataset
url <- "https://raw.githubusercontent.com/americanpanorama/Census_HOLC_Research/main/2020_Census_Tracts/Tracts_2020_HOLC.geojson"
holc_data <- st_read(url)

kable(head(holc_data))
# Plot the data
ggplot() +
  geom_sf(data = holc_data) +
  theme_minimal() +
  ggtitle("2020 Census Tracts with HOLC Data")
```


Downloading and plotting the dataset in Python:

Python code:

```{python, cache=TRUE, eval=FALSE}
# Import libraries
import geopandas as gpd

# Download the dataset
url = "https://raw.githubusercontent.com/americanpanorama/Census_HOLC_Research/main/2020_Census_Tracts/Tracts_2020_HOLC.geojson"
holc_data = gpd.read_file(url)

# Display the data as a table
print(holc_data)

# Plot the data
holc_data.plot()
plot.title("2020 Census Tracts with HOLC Data")
plot.show()

```


In both R and Python, the code downloads the dataset, reads the Shapefile, and plots the data using ggplot2 in R and geopandas in Python. Make sure to install the necessary packages before running the code.